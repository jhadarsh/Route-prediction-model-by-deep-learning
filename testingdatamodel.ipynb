{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c65518a-5f90-4617-86c2-56f12ecb15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef925ec-2593-48f4-b092-e282b66d176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0411 - mae: 0.8722 - val_loss: 0.9982 - val_mae: 0.8537\n",
      "Epoch 2/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9872 - mae: 0.8485 - val_loss: 0.9974 - val_mae: 0.8538\n",
      "Epoch 3/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9904 - mae: 0.8504 - val_loss: 0.9972 - val_mae: 0.8544\n",
      "Epoch 4/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9946 - mae: 0.8531 - val_loss: 0.9971 - val_mae: 0.8542\n",
      "Epoch 5/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9866 - mae: 0.8477 - val_loss: 0.9975 - val_mae: 0.8549\n",
      "Epoch 6/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9923 - mae: 0.8494 - val_loss: 0.9970 - val_mae: 0.8545\n",
      "Epoch 7/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0064 - mae: 0.8574 - val_loss: 0.9977 - val_mae: 0.8537\n",
      "Epoch 8/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9974 - mae: 0.8536 - val_loss: 0.9977 - val_mae: 0.8540\n",
      "Epoch 9/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0021 - mae: 0.8563 - val_loss: 0.9971 - val_mae: 0.8543\n",
      "Epoch 10/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9964 - mae: 0.8519 - val_loss: 0.9974 - val_mae: 0.8543\n",
      "Epoch 11/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9965 - mae: 0.8520 - val_loss: 0.9977 - val_mae: 0.8536\n",
      "Epoch 12/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0048 - mae: 0.8577 - val_loss: 0.9973 - val_mae: 0.8549\n",
      "Epoch 13/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9951 - mae: 0.8523 - val_loss: 0.9974 - val_mae: 0.8545\n",
      "Epoch 14/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9947 - mae: 0.8532 - val_loss: 0.9975 - val_mae: 0.8546\n",
      "Epoch 15/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0158 - mae: 0.8624 - val_loss: 0.9974 - val_mae: 0.8541\n",
      "Epoch 16/300\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9953 - mae: 0.8514 - val_loss: 0.9971 - val_mae: 0.8543\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: -0.0002939636232248517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Predicted Route Details:\n",
      "Start: Connaught Place, Delhi\n",
      "Destination: Noida, Delhi\n",
      "Via Road: NH44\n",
      "Distance (km): 27.28095054626465\n",
      "Signals: 8\n",
      "Congestion Count: 1\n",
      "Waterlogging Count: 0\n",
      "Route Type: Internal Road\n",
      "Time (Car): 70.90190887451172\n",
      "Time (Bike): 55.53883743286133\n",
      "Time (Cycle): 129.72499084472656\n",
      "Time (Bus): 64.28028869628906\n",
      "Time (Metro): 42.468170166015625\n",
      "Total Time: 11.168441772460938\n",
      "Min Time: 4.6823225021362305\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"delhi_routes.csv\")\n",
    "\n",
    "# Handling Missing Values\n",
    "df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Encoding Categorical Features\n",
    "label_encoders = {}\n",
    "for col in [\"Start\", \"Destination\", \"Via Road\", \"Route Type\"]:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Features and Targets\n",
    "X = df[[\"Start\", \"Destination\"]].values\n",
    "y = df.drop(columns=[\"Start\", \"Destination\", \"Congestion Points\", \"Waterlogging Points\"]).values\n",
    "\n",
    "# Normalize Target Variables\n",
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "# Save Encoders and Scaler\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build Optimized ANN Model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y.shape[1], activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.005), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train Model with Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# Save Model\n",
    "model.save(\"ann_route_prediction.h5\")\n",
    "\n",
    "# Load Model and Run Example Test\n",
    "model = load_model(\"ann_route_prediction.h5\")\n",
    "label_encoders = joblib.load(\"label_encoders.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "example_start = \"Connaught Place, Delhi\"\n",
    "example_dest = \"Noida, Delhi\"\n",
    "example_input = np.array([[label_encoders[\"Start\"].transform([example_start])[0], \n",
    "                            label_encoders[\"Destination\"].transform([example_dest])[0]]])\n",
    "example_pred = model.predict(example_input)\n",
    "example_output = scaler.inverse_transform(example_pred)[0]\n",
    "\n",
    "predicted_details = {\n",
    "    \"Start\": example_start,\n",
    "    \"Destination\": example_dest,\n",
    "    \"Via Road\": label_encoders[\"Via Road\"].inverse_transform([int(example_output[0])])[0],\n",
    "    \"Distance (km)\": example_output[1],\n",
    "    \"Signals\": int(example_output[2]),\n",
    "    \"Congestion Count\": int(example_output[3]),\n",
    "    \"Waterlogging Count\": int(example_output[4]),\n",
    "    \"Route Type\": label_encoders[\"Route Type\"].inverse_transform([int(example_output[5])])[0],\n",
    "    \"Time (Car)\": example_output[6],\n",
    "    \"Time (Bike)\": example_output[7],\n",
    "    \"Time (Cycle)\": example_output[8],\n",
    "    \"Time (Bus)\": example_output[9],\n",
    "    \"Time (Metro)\": example_output[10],\n",
    "    \"Total Time\": example_output[11],\n",
    "    \"Min Time\": example_output[12]\n",
    "}\n",
    "\n",
    "print(\"Predicted Route Details:\")\n",
    "for key, value in predicted_details.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcb595-860a-49c9-a464-6fae81155944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
